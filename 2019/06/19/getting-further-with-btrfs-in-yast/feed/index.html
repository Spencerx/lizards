<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: Getting further with Btrfs in YaST</title>
	<atom:link href="https://lizards.opensuse.org/2019/06/19/getting-further-with-btrfs-in-yast/feed/" rel="self" type="application/rss+xml" />
	<link>https://lizards.opensuse.org/2019/06/19/getting-further-with-btrfs-in-yast/</link>
	<description>Blogs and Ramblings of the openSUSE Members</description>
	<lastBuildDate>Fri, 06 Mar 2020 17:50:09 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>

	<item>
		<title>By: ensin</title>
		<link>https://lizards.opensuse.org/2019/06/19/getting-further-with-btrfs-in-yast/#comment-16893</link>
		<dc:creator><![CDATA[ensin]]></dc:creator>
		<pubDate>Mon, 24 Jun 2019 17:24:53 +0000</pubDate>
		<guid isPermaLink="false">http://lizards.opensuse.org/?p=13814#comment-16893</guid>
		<description><![CDATA[Thank you for sharing your btrfs insights.

It&#039;s really unfortunate the btrfs &quot;raid&quot; seems to behave that differently than what one would expect from raid device.

With the udev rules and policy settings in mdraid, it creates no need for &quot;managing a degraded array&quot;. If enabled, detatching and attaching back is a hot-plug non-issue. So maybe the btrfs could also be solved with just some udev rules hooking on device events.]]></description>
		<content:encoded><![CDATA[<p>Thank you for sharing your btrfs insights.</p>
<p>It&#8217;s really unfortunate the btrfs &#8220;raid&#8221; seems to behave that differently than what one would expect from raid device.</p>
<p>With the udev rules and policy settings in mdraid, it creates no need for &#8220;managing a degraded array&#8221;. If enabled, detatching and attaching back is a hot-plug non-issue. So maybe the btrfs could also be solved with just some udev rules hooking on device events.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Tony Su</title>
		<link>https://lizards.opensuse.org/2019/06/19/getting-further-with-btrfs-in-yast/#comment-16892</link>
		<dc:creator><![CDATA[Tony Su]]></dc:creator>
		<pubDate>Mon, 24 Jun 2019 16:59:48 +0000</pubDate>
		<guid isPermaLink="false">http://lizards.opensuse.org/?p=13814#comment-16892</guid>
		<description><![CDATA[I would suggest exploring your scenario in a virtual machine (any virtualization including Virtualbox, VMware, KVM, etc) to be familiar with what happens and what to do.

Any questions can be posted to the Technical Help Forums (Installation)]]></description>
		<content:encoded><![CDATA[<p>I would suggest exploring your scenario in a virtual machine (any virtualization including Virtualbox, VMware, KVM, etc) to be familiar with what happens and what to do.</p>
<p>Any questions can be posted to the Technical Help Forums (Installation)</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Tony Su</title>
		<link>https://lizards.opensuse.org/2019/06/19/getting-further-with-btrfs-in-yast/#comment-16891</link>
		<dc:creator><![CDATA[Tony Su]]></dc:creator>
		<pubDate>Mon, 24 Jun 2019 16:56:08 +0000</pubDate>
		<guid isPermaLink="false">http://lizards.opensuse.org/?p=13814#comment-16891</guid>
		<description><![CDATA[I&#039;ve collected and posted links to better sources of BTRFS info (IMO)
Although is quite a bit of info and different sources to read, IMO it covers what I feel is the most important info authoritatively and most common scenarios

https://en.opensuse.org/User:Tsu2/systemd-1#BTRFS

From one of the links in my above Wiki,
I haven&#039;t yet found anything new, better or different for creating, modifying adding or replacing a disk or otherwise managing a degraded array than what is in the BTRFS Wiki
https://btrfs.wiki.kernel.org/index.php/Using_Btrfs_with_Multiple_Devices

Yes, I agree there is a future for YaST module(s) that can simplify BTRFS RAID management beyond initial setup.]]></description>
		<content:encoded><![CDATA[<p>I&#8217;ve collected and posted links to better sources of BTRFS info (IMO)<br />
Although is quite a bit of info and different sources to read, IMO it covers what I feel is the most important info authoritatively and most common scenarios</p>
<p><a href="https://en.opensuse.org/User:Tsu2/systemd-1#BTRFS" rel="nofollow">https://en.opensuse.org/User:Tsu2/systemd-1#BTRFS</a></p>
<p>From one of the links in my above Wiki,<br />
I haven&#8217;t yet found anything new, better or different for creating, modifying adding or replacing a disk or otherwise managing a degraded array than what is in the BTRFS Wiki<br />
<a href="https://btrfs.wiki.kernel.org/index.php/Using_Btrfs_with_Multiple_Devices" rel="nofollow">https://btrfs.wiki.kernel.org/index.php/Using_Btrfs_with_Multiple_Devices</a></p>
<p>Yes, I agree there is a future for YaST module(s) that can simplify BTRFS RAID management beyond initial setup.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: ensin</title>
		<link>https://lizards.opensuse.org/2019/06/19/getting-further-with-btrfs-in-yast/#comment-16888</link>
		<dc:creator><![CDATA[ensin]]></dc:creator>
		<pubDate>Mon, 24 Jun 2019 01:20:37 +0000</pubDate>
		<guid isPermaLink="false">http://lizards.opensuse.org/?p=13814#comment-16888</guid>
		<description><![CDATA[I mean will the filesystem continue to work (whithout manual intervention) when a drive fails or is removed during operation or while the machine was turned off, so that the redundancy is reduced, but operation is still possible?

Will btrfs start duplicating files on a single remaining disk in a strange attempt to &quot;maintain data redundancy&quot;?

And will the filesystem automatically re-sync a working spinning hard drive, that has been removed or turned off, with an SSD say in a laptop, after the hard drive has been plugged in or turned on again?]]></description>
		<content:encoded><![CDATA[<p>I mean will the filesystem continue to work (whithout manual intervention) when a drive fails or is removed during operation or while the machine was turned off, so that the redundancy is reduced, but operation is still possible?</p>
<p>Will btrfs start duplicating files on a single remaining disk in a strange attempt to &#8220;maintain data redundancy&#8221;?</p>
<p>And will the filesystem automatically re-sync a working spinning hard drive, that has been removed or turned off, with an SSD say in a laptop, after the hard drive has been plugged in or turned on again?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: ensin</title>
		<link>https://lizards.opensuse.org/2019/06/19/getting-further-with-btrfs-in-yast/#comment-16885</link>
		<dc:creator><![CDATA[ensin]]></dc:creator>
		<pubDate>Sun, 23 Jun 2019 10:45:10 +0000</pubDate>
		<guid isPermaLink="false">http://lizards.opensuse.org/?p=13814#comment-16885</guid>
		<description><![CDATA[Have you been able to solve the fundamental problem of btrfs &quot;raid&quot;?

That is that instead of provicing a rubust, redundant array of individual disks, it provides a &quot;broken multi-disk setup&quot; whenever a disk fails or gets replaced phyisically, which requires manual fixing.

Have you been able to automate this with auxiliary scripts?]]></description>
		<content:encoded><![CDATA[<p>Have you been able to solve the fundamental problem of btrfs &#8220;raid&#8221;?</p>
<p>That is that instead of provicing a rubust, redundant array of individual disks, it provides a &#8220;broken multi-disk setup&#8221; whenever a disk fails or gets replaced phyisically, which requires manual fixing.</p>
<p>Have you been able to automate this with auxiliary scripts?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Tony Su</title>
		<link>https://lizards.opensuse.org/2019/06/19/getting-further-with-btrfs-in-yast/#comment-16878</link>
		<dc:creator><![CDATA[Tony Su]]></dc:creator>
		<pubDate>Fri, 21 Jun 2019 03:15:56 +0000</pubDate>
		<guid isPermaLink="false">http://lizards.opensuse.org/?p=13814#comment-16878</guid>
		<description><![CDATA[Well I can report a first successful experiment of what I&#039;d consider one common scenario, although it&#039;s not supported by YaST.

Objective - 
New Install Tumbleweed on BTRFS RAID 10 using VMWare Workstation 15

Obstacle 1
VMware does not support installing a new machine on more than one block device, so the most direct scenario is not possible. But, it means that another related scenario can now be explored, converting a default TW install from a BTRFS root fs on a single disk to a RAID10 on multiple disks after install.

Step 1 install TW latest with intention to use YaST Partitioner as much as possible.
Then add 4 empty virtual disks after install.

Obstacle 2
Found that YaST Partitioner cannot add block devices to the mounted root file system device.
Seems YaST can create a new PROFILE (RAID Level and device group) with anything that&#039;s not root, without further investigation don&#039;t know if it&#039;s because root is mounted or it&#039;s just root. Since I cannot expand/add to the existing BTRFS fs using YaST, what follows can be done only with BTRFS tools.

Step 2 (or Step 1 using BTRFS tools)
Display BTRFS on current system, note that &quot;filesystem&quot; can be abbreviated &quot;fi&quot;&#039;

btrfs fi show
Label: none  uuid: 9caca3c8-8b24-4754-bc44-1d4dcdf0ec4f
        Total devices 5 FS bytes used 3.93GiB
        devid    1 size 18.62GiB used 5.02GiB path /dev/sda2
        devid    2 size 20.00GiB used 0.00B path /dev/sdb
        devid    3 size 20.00GiB used 0.00B path /dev/sdc
        devid    4 size 20.00GiB used 0.00B path /dev/sdd
        devid    5 size 20.00GiB used 0.00B path /dev/sde

Note that devid 1 has something on it from my early experimentation creating a btrfs filesystem without RAID, and is why I will have to use &quot;-f&quot; to force striping in the following command. Am skipping my attempt without forcing which threw a surprising &quot;No space left on device&quot; error (which of course isn&#039;t true)

Step 3 Execute conversion to RAID10

btrfs balance start -dconvert=raid10 -mconvert=raid10 /
Done, had to relocate 9 out of 9 chunks

Step 4
Success! The following command verifies

btrfs fi df .
Data, RAID10: total=8.00GiB, used=3.78GiB
System, RAID10: total=64.00MiB, used=16.00KiB
Metadata, RAID10: total=5.00GiB, used=159.41MiB
GlobalReserve, single: total=16.00MiB, used=16.00KiB]]></description>
		<content:encoded><![CDATA[<p>Well I can report a first successful experiment of what I&#8217;d consider one common scenario, although it&#8217;s not supported by YaST.</p>
<p>Objective &#8211;<br />
New Install Tumbleweed on BTRFS RAID 10 using VMWare Workstation 15</p>
<p>Obstacle 1<br />
VMware does not support installing a new machine on more than one block device, so the most direct scenario is not possible. But, it means that another related scenario can now be explored, converting a default TW install from a BTRFS root fs on a single disk to a RAID10 on multiple disks after install.</p>
<p>Step 1 install TW latest with intention to use YaST Partitioner as much as possible.<br />
Then add 4 empty virtual disks after install.</p>
<p>Obstacle 2<br />
Found that YaST Partitioner cannot add block devices to the mounted root file system device.<br />
Seems YaST can create a new PROFILE (RAID Level and device group) with anything that&#8217;s not root, without further investigation don&#8217;t know if it&#8217;s because root is mounted or it&#8217;s just root. Since I cannot expand/add to the existing BTRFS fs using YaST, what follows can be done only with BTRFS tools.</p>
<p>Step 2 (or Step 1 using BTRFS tools)<br />
Display BTRFS on current system, note that &#8220;filesystem&#8221; can be abbreviated &#8220;fi&#8221;&#8216;</p>
<p>btrfs fi show<br />
Label: none  uuid: 9caca3c8-8b24-4754-bc44-1d4dcdf0ec4f<br />
        Total devices 5 FS bytes used 3.93GiB<br />
        devid    1 size 18.62GiB used 5.02GiB path /dev/sda2<br />
        devid    2 size 20.00GiB used 0.00B path /dev/sdb<br />
        devid    3 size 20.00GiB used 0.00B path /dev/sdc<br />
        devid    4 size 20.00GiB used 0.00B path /dev/sdd<br />
        devid    5 size 20.00GiB used 0.00B path /dev/sde</p>
<p>Note that devid 1 has something on it from my early experimentation creating a btrfs filesystem without RAID, and is why I will have to use &#8220;-f&#8221; to force striping in the following command. Am skipping my attempt without forcing which threw a surprising &#8220;No space left on device&#8221; error (which of course isn&#8217;t true)</p>
<p>Step 3 Execute conversion to RAID10</p>
<p>btrfs balance start -dconvert=raid10 -mconvert=raid10 /<br />
Done, had to relocate 9 out of 9 chunks</p>
<p>Step 4<br />
Success! The following command verifies</p>
<p>btrfs fi df .<br />
Data, RAID10: total=8.00GiB, used=3.78GiB<br />
System, RAID10: total=64.00MiB, used=16.00KiB<br />
Metadata, RAID10: total=5.00GiB, used=159.41MiB<br />
GlobalReserve, single: total=16.00MiB, used=16.00KiB</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Yast Team</title>
		<link>https://lizards.opensuse.org/2019/06/19/getting-further-with-btrfs-in-yast/#comment-16876</link>
		<dc:creator><![CDATA[Yast Team]]></dc:creator>
		<pubDate>Thu, 20 Jun 2019 10:28:04 +0000</pubDate>
		<guid isPermaLink="false">http://lizards.opensuse.org/?p=13814#comment-16876</guid>
		<description><![CDATA[Even if the article sounds a bit enthusiastic about the Btrfs capabilities, is not YaST (or YaST Team) intention to endorse any concrete technology. The goal of the Partitioner is to offer the same level of support for MD RAID, LVM, Bcache and Btrfs and to make easy to use every technology on its own or to combine all of them into a single setup.

In other words, despite the goal of Btrfs developers to include LVM and/or RAID capabilities at file system level so you can live without those other technologies, Btrfs is (still) not a full replacement and there may be situations in which the usage of the most mature LVM/RAID is preferred.

It depends on the use case, but as you mentioned, is probably worth a try and some experiments. We encourage to have fun with it!

If you want to go beyond the Btrfs capabilities offered by YaST (that are admittedly a very small subset of all what Btrfs can do), the official Btrfs wiki would be a good place to start. https://btrfs.wiki.kernel.org]]></description>
		<content:encoded><![CDATA[<p>Even if the article sounds a bit enthusiastic about the Btrfs capabilities, is not YaST (or YaST Team) intention to endorse any concrete technology. The goal of the Partitioner is to offer the same level of support for MD RAID, LVM, Bcache and Btrfs and to make easy to use every technology on its own or to combine all of them into a single setup.</p>
<p>In other words, despite the goal of Btrfs developers to include LVM and/or RAID capabilities at file system level so you can live without those other technologies, Btrfs is (still) not a full replacement and there may be situations in which the usage of the most mature LVM/RAID is preferred.</p>
<p>It depends on the use case, but as you mentioned, is probably worth a try and some experiments. We encourage to have fun with it!</p>
<p>If you want to go beyond the Btrfs capabilities offered by YaST (that are admittedly a very small subset of all what Btrfs can do), the official Btrfs wiki would be a good place to start. <a href="https://btrfs.wiki.kernel.org" rel="nofollow">https://btrfs.wiki.kernel.org</a></p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Yast Team</title>
		<link>https://lizards.opensuse.org/2019/06/19/getting-further-with-btrfs-in-yast/#comment-16875</link>
		<dc:creator><![CDATA[Yast Team]]></dc:creator>
		<pubDate>Thu, 20 Jun 2019 09:23:11 +0000</pubDate>
		<guid isPermaLink="false">http://lizards.opensuse.org/?p=13814#comment-16875</guid>
		<description><![CDATA[No, we don&#039;t consider RAID 5/6 in Btrfs to be &quot;enterprise ready&quot;, so to speak. If you look to the screenshot illustrating the creation of a new Btrfs you will notice YaST only offers  &quot;single&quot;, &quot;dup&quot;, &quot;RAID0&quot;, &quot;RAID1&quot; and &quot;RAID10&quot; as possible RAID levels.

Raid 5 and 6 are technically implemented in some of the tools offered by the distribution and they can be used. But you will have to use the native Btrfs tools to configure it, instead of YaST.

Those Btrfs RAID levels are not officially supported in SUSE Linux Enterprise, which means if you use them you are basically on your own. Of course, it&#039;s also available in openSUSE Tumbleweed and Leap, but with the same level of stability (that is, use it at your own risk).]]></description>
		<content:encoded><![CDATA[<p>No, we don&#8217;t consider RAID 5/6 in Btrfs to be &#8220;enterprise ready&#8221;, so to speak. If you look to the screenshot illustrating the creation of a new Btrfs you will notice YaST only offers  &#8220;single&#8221;, &#8220;dup&#8221;, &#8220;RAID0&#8221;, &#8220;RAID1&#8221; and &#8220;RAID10&#8221; as possible RAID levels.</p>
<p>Raid 5 and 6 are technically implemented in some of the tools offered by the distribution and they can be used. But you will have to use the native Btrfs tools to configure it, instead of YaST.</p>
<p>Those Btrfs RAID levels are not officially supported in SUSE Linux Enterprise, which means if you use them you are basically on your own. Of course, it&#8217;s also available in openSUSE Tumbleweed and Leap, but with the same level of stability (that is, use it at your own risk).</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Raider of the lost Sector</title>
		<link>https://lizards.opensuse.org/2019/06/19/getting-further-with-btrfs-in-yast/#comment-16874</link>
		<dc:creator><![CDATA[Raider of the lost Sector]]></dc:creator>
		<pubDate>Thu, 20 Jun 2019 08:05:25 +0000</pubDate>
		<guid isPermaLink="false">http://lizards.opensuse.org/?p=13814#comment-16874</guid>
		<description><![CDATA[Does that mean btrfs RAID 5/6 is now finally stable, or can you still expect it to eat your data?]]></description>
		<content:encoded><![CDATA[<p>Does that mean btrfs RAID 5/6 is now finally stable, or can you still expect it to eat your data?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Tony Su</title>
		<link>https://lizards.opensuse.org/2019/06/19/getting-further-with-btrfs-in-yast/#comment-16869</link>
		<dc:creator><![CDATA[Tony Su]]></dc:creator>
		<pubDate>Wed, 19 Jun 2019 16:41:33 +0000</pubDate>
		<guid isPermaLink="false">http://lizards.opensuse.org/?p=13814#comment-16869</guid>
		<description><![CDATA[Very Cool.
Aside from quibbling about paired/unimpaired and dispensable/indispensable in the article, if BTRFS wants to provide full RAID replacement capability, should support RAID 01 as well.

Although I have religiously avoided software RAID in favor of hardware, this sounds interesting enough to experiment with. Will be looking for full documentation on not just setup but management, breaking sets and recovery. And, possibly guidance on using dissimilar block devices and if there are limitations, particularly in numbers of spindles.]]></description>
		<content:encoded><![CDATA[<p>Very Cool.<br />
Aside from quibbling about paired/unimpaired and dispensable/indispensable in the article, if BTRFS wants to provide full RAID replacement capability, should support RAID 01 as well.</p>
<p>Although I have religiously avoided software RAID in favor of hardware, this sounds interesting enough to experiment with. Will be looking for full documentation on not just setup but management, breaking sets and recovery. And, possibly guidance on using dissimilar block devices and if there are limitations, particularly in numbers of spindles.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
